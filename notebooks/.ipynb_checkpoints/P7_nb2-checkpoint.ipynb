{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd63dab9-23d6-4509-a8c3-6b87596aa152",
   "metadata": {},
   "source": [
    "# temps de debut execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "87c6f73d-9745-4ae1-926e-9ea4b972781a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exécution du notebook commencée à: 2024-06-28 13:11:11.902748\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "# Marquer le début de l'exécution\n",
    "start_time = time.time()\n",
    "print(f\"Exécution du notebook commencée à: {datetime.datetime.now()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21cc966-809d-441f-9d1b-f01fa7e9f526",
   "metadata": {},
   "source": [
    "# Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b861bfab-0697-4663-9595-40cb7b2411aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- TARGET\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m scalerAPI \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Appliquer l'imputation et la standardisation sur le DataFrame\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m app_datas_imputed \u001b[38;5;241m=\u001b[39m imputerAPI\u001b[38;5;241m.\u001b[39mtransform(app_datas)\n\u001b[1;32m     60\u001b[0m app_datas_scaled \u001b[38;5;241m=\u001b[39m scalerAPI\u001b[38;5;241m.\u001b[39mtransform(app_datas_imputed)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Convertir le résultat en DataFrame et conserver les colonnes originales\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/stabadenvP7/lib/python3.12/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/stabadenvP7/lib/python3.12/site-packages/sklearn/impute/_knn.py:266\u001b[0m, in \u001b[0;36mKNNImputer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    265\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 266\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    267\u001b[0m     X,\n\u001b[1;32m    268\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    269\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES,\n\u001b[1;32m    270\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[1;32m    271\u001b[0m     copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy,\n\u001b[1;32m    272\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    273\u001b[0m )\n\u001b[1;32m    275\u001b[0m mask \u001b[38;5;241m=\u001b[39m _get_mask(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing_values)\n\u001b[1;32m    276\u001b[0m mask_fit_X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mask_fit_X\n",
      "File \u001b[0;32m~/anaconda3/envs/stabadenvP7/lib/python3.12/site-packages/sklearn/base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    545\u001b[0m ):\n\u001b[1;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \n\u001b[1;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/stabadenvP7/lib/python3.12/site-packages/sklearn/base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m     )\n\u001b[0;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- TARGET\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Configurer MLflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"Credit Risk Model\")\n",
    "\n",
    "# Charger le DataFrame\n",
    "app_datas = pd.read_csv('../csv_files/app_datas_light.csv')\n",
    "\n",
    "# Mode débogage\n",
    "debug_mode = True\n",
    "\n",
    "if debug_mode:\n",
    "    # Utiliser un sous-ensemble du dataset pour le débogage\n",
    "    app_datas = app_datas.sample(frac=0.15, random_state=42)\n",
    "\n",
    "# Séparer les features et la cible\n",
    "X = app_datas.drop(columns=['TARGET'])\n",
    "y = app_datas['TARGET']\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Créer un pipeline avec imputation KNN, standardisation et SMOTE\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', KNNImputer(n_neighbors=3)),  # Imputation des valeurs manquantes\n",
    "    ('scaler', StandardScaler()),  # Standardisation des caractéristiques\n",
    "    ('smote', SMOTE(sampling_strategy=0.3, random_state=42))  # Équilibrage des classes avec SMOTE\n",
    "])\n",
    "\n",
    "# Appliquer le pipeline sur les données d'entraînement\n",
    "X_train_resampled, y_train_resampled = pipeline.fit_resample(X_train, y_train)\n",
    "\n",
    "# Transformer les données de test sans SMOTE\n",
    "X_test_imputed = pipeline.named_steps['imputer'].transform(X_test)\n",
    "X_test_scaled = pipeline.named_steps['scaler'].transform(X_test_imputed)\n",
    "\n",
    "# création d'un dataframe imputed et scaled pour la prédiction dans l'aPI\n",
    "\n",
    "# Utiliser les étapes d'imputation et de standardisation du pipeline existant\n",
    "imputerAPI = pipeline.named_steps['imputer']\n",
    "scalerAPI = pipeline.named_steps['scaler']\n",
    "\n",
    "# Appliquer l'imputation et la standardisation sur le DataFrame\n",
    "app_datas_imputed = imputerAPI.transform(app_datas)\n",
    "app_datas_scaled = scalerAPI.transform(app_datas_imputed)\n",
    "\n",
    "# Convertir le résultat en DataFrame et conserver les colonnes originales\n",
    "app_datas_imputed_scaled = pd.DataFrame(app_datas_scaled, columns=app_datas.columns)\n",
    "\n",
    "# Sauvegarder le DataFrame résultant dans un fichier CSV\n",
    "app_datas_imputed_scaled.to_csv('../csv_files/app_datas_light_imputed_scaled.csv', index=False)\n",
    "\n",
    "\n",
    "print(f\"Shape of X_train: {X_train_resampled.shape}\")\n",
    "print(f\"Shape of X_test: {X_test_scaled.shape}\")\n",
    "print(f\"Distribution in y_train: {pd.Series(y_train_resampled).value_counts(normalize=True)}\")\n",
    "print(f\"Distribution in y_test: {pd.Series(y_test).value_counts(normalize=True)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261713ec-b886-4eca-b038-4f50e2490060",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_datas['SK_ID_CURR']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70fdffa-8685-4e68-81f5-8ffa7531f3bc",
   "metadata": {},
   "source": [
    "# Modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28b8377-df59-40ef-9489-9158c89f7e96",
   "metadata": {},
   "source": [
    "## fonction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6a7f78-da47-4d75-b0db-e6043bff5e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "\n",
    "def evaluate_and_log_model(model, model_name, model_type, params, X_train, y_train, X_test, y_test):\n",
    "    with mlflow.start_run():\n",
    "        # Entraîner le modèle\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Prédictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Évaluer les performances\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        fp = conf_matrix[0][1]\n",
    "        fn = conf_matrix[1][0]\n",
    "        cost = fp + 10 * fn\n",
    "\n",
    "        # Logger les métriques et les hyperparamètres\n",
    "        mlflow.log_metric(\"AUC\", auc)\n",
    "        mlflow.log_metric(\"Accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"Cost\", cost)\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_param(\"model_type\", model_type)\n",
    "        \n",
    "        # Enregistrer le modèle\n",
    "        mlflow.sklearn.log_model(model, model_name)\n",
    "        \n",
    "        print(f\"{model_name} - AUC: {auc}\")\n",
    "        print(f\"{model_name} - Accuracy: {accuracy}\")\n",
    "        print(f\"{model_name} - Cost: {cost}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4183294e-7bd9-48ee-bc0f-9d790f4dcee0",
   "metadata": {},
   "source": [
    "## Modèle Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a14bfe-b7b4-4338-b816-4b47f4190b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_params = {\"strategy\": \"most_frequent\"}\n",
    "dummy_clf = DummyClassifier(**dummy_params)\n",
    "evaluate_and_log_model(dummy_clf, \"dummy_classifier_model\", \"Dummy Classifier\", dummy_params, X_train_resampled, y_train_resampled, X_test_scaled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd64759-ad51-470b-8b78-6e366cb134ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1ddd36-c870-451c-8e7a-95caa5896189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8dd353a-b809-4a21-9586-e3eba7b72b52",
   "metadata": {},
   "source": [
    "## Modèle Regression lineaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4d4f4a-2f0a-4299-b542-4b48fce1b3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg_params = {\n",
    "    \"penalty\": 'l2',\n",
    "    \"C\": 1.0,\n",
    "    \"class_weight\": 'balanced',\n",
    "    \"random_state\": 42,\n",
    "    \"max_iter\": 1000\n",
    "}\n",
    "log_reg = LogisticRegression(**log_reg_params)\n",
    "evaluate_and_log_model(log_reg, \"logistic_regression_model\", \"Logistic Regression\", log_reg_params, X_train_resampled, y_train_resampled, X_test_scaled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82551c02-2cda-4ab9-9292-4db31a1386a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da659b3b-cd82-4a1d-8b85-73cc378b207b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f30c6e1b-c4e0-4012-825b-3e78965ffe48",
   "metadata": {},
   "source": [
    "## Modèle Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c854c5d-5ded-4f5b-a88a-89125b8e5ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_params = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"class_weight\": 'balanced',\n",
    "    \"random_state\": 42\n",
    "}\n",
    "rf_clf = RandomForestClassifier(**rf_params)\n",
    "evaluate_and_log_model(rf_clf, \"random_forest_model\", \"Random Forest\", rf_params, X_train_resampled, y_train_resampled, X_test_scaled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb407721-a4d3-4bbf-9c02-456ee0bda9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5d2ed3-2aba-4c60-b0dc-fa6676162dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8be32d8c-0e04-4366-b32c-f7e14d48a00f",
   "metadata": {},
   "source": [
    "## Modèle XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb939a20-eaff-4b15-8d74-5e17e721fec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_params = {\n",
    "    \"objective\": 'binary:logistic',\n",
    "    \"random_state\": 42,\n",
    "    \"eval_metric\": 'auc'\n",
    "}\n",
    "xgb_clf = XGBClassifier(**xgb_params)\n",
    "evaluate_and_log_model(xgb_clf, \"xgboost_model\", \"XGBoost\", xgb_params, X_train_resampled, y_train_resampled, X_test_scaled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c718e9-bebc-414f-ab1d-62fc5c3162a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de55d6af-192e-46d9-8498-b88764423cd7",
   "metadata": {},
   "source": [
    "## création du score personnalisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38b9f6e-ffc1-4619-aadb-62ec6ea0f412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339600d9-6c5c-4764-8931-e7155e1cc5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, confusion_matrix\n",
    "\n",
    "# Définir une fonction pour calculer le coût\n",
    "def custom_cost(y_true, y_pred):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    fp = conf_matrix[0][1]\n",
    "    fn = conf_matrix[1][0]\n",
    "    cost = fp + 10 * fn\n",
    "    return cost\n",
    "\n",
    "# Créer un make_scorer à partir de la fonction custom_cost\n",
    "cost_scorer = make_scorer(custom_cost, greater_is_better=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07d1675-f381-48dd-bf6b-cc4b27f502a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eddae018-46a1-4339-a1d4-1b06ef856bcf",
   "metadata": {},
   "source": [
    "## Gridsearchcv sur XGBOost et log mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4808bf-0984-42e5-b129-015fab142689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508e1e0f-5fd0-4321-b54a-1a07beb1d0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Définir les hyperparamètres à tester\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Créer le modèle XGBoost\n",
    "xgb_clf = XGBClassifier(objective='binary:logistic', random_state=42)\n",
    "\n",
    "# Configurer GridSearchCV avec le score personnalisé\n",
    "grid_search = GridSearchCV(estimator=xgb_clf, param_grid=param_grid, scoring=cost_scorer, cv=3, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fonction pour évaluer et enregistrer les résultats de GridSearchCV dans MLflow\n",
    "def log_grid_search_cv_results(grid_search, X_train, y_train, X_test, y_test):\n",
    "    with mlflow.start_run():\n",
    "        # Loguer le type de modèle\n",
    "        mlflow.log_param(\"model_type\", \"XGBoost with GridSearchCV\")\n",
    "        \n",
    "        # Entraîner le GridSearchCV\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Logger tous les résultats de GridSearchCV\n",
    "        cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "        for i in range(len(cv_results)):\n",
    "            for key in cv_results.columns:\n",
    "                value = cv_results[key].iloc[i]\n",
    "                if isinstance(value, (float, int, np.number)):\n",
    "                    mlflow.log_metric(f\"{key}_{i}\", value)\n",
    "                elif isinstance(value, (list, dict)):\n",
    "                    # Convert lists or dicts to a string representation\n",
    "                    mlflow.log_param(f\"{key}_{i}\", str(value))\n",
    "        \n",
    "        # Enregistrer les meilleurs hyperparamètres\n",
    "        best_params = grid_search.best_params_\n",
    "        mlflow.log_params(best_params)\n",
    "       \n",
    "        \n",
    "        # Afficher les meilleurs hyperparamètres\n",
    "        print(\"Best Hyperparameters:\", best_params)\n",
    "        \n",
    "        # Enregistrer le meilleur modèle\n",
    "        best_model = grid_search.best_estimator_\n",
    "        mlflow.sklearn.log_model(best_model, \"best_xgboost_model\")\n",
    "\n",
    "        # Sauvegarder le modèle localement dans le dossier 'models'\n",
    "        model_path = '../models/best_xgboost_model.pkl'\n",
    "        os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "        joblib.dump(best_model, model_path)\n",
    "        print(f\"Best model saved to {model_path}\")\n",
    "        \n",
    "        # Prédictions avec le meilleur modèle\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Évaluer les performances\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        fp = conf_matrix[0][1]\n",
    "        fn = conf_matrix[1][0]\n",
    "        cost = fp + 10 * fn\n",
    "        \n",
    "        # Logger les métriques\n",
    "        mlflow.log_metric(\"AUC\", auc)\n",
    "        mlflow.log_metric(\"Accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"Cost\", cost)\n",
    "        \n",
    "        print(f\"Best Model - AUC: {auc}\")\n",
    "        print(f\"Best Model - Accuracy: {accuracy}\")\n",
    "        print(f\"Best Model - Cost: {cost}\")\n",
    "\n",
    "# Exécuter la fonction pour loguer les résultats de GridSearchCV\n",
    "log_grid_search_cv_results(grid_search, X_train_resampled, y_train_resampled, X_test_scaled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416d707e-5165-40a7-96fd-6a0b0c460b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d1a8439-dd14-4590-bcc0-faa8fd731631",
   "metadata": {},
   "source": [
    "## GridSearchCV avec Pipelines\n",
    "\n",
    "L'intégration de pipelines dans le processus de GridSearch présente plusieurs avantages, notamment la simplification du flux de travail, l'élimination des fuites de données et l'automatisation des étapes de prétraitement. Voici comment et pourquoi vous pouvez intégrer des pipelines dans votre code de GridSearch.\n",
    "Avantages de l'Intégration de Pipelines\n",
    "\n",
    "    Simplification du Flux de Travail :\n",
    "        En intégrant les étapes de prétraitement et de modélisation dans un pipeline, le code devient plus propre et plus facile à comprendre.\n",
    "\n",
    "    Élimination des Fuites de Données :\n",
    "        Lors de la validation croisée, il est crucial que les étapes de prétraitement soient ajustées uniquement sur les données d'entraînement et non sur les données de validation. Les pipelines assurent cette séparation.\n",
    "\n",
    "    Automatisation et Reproductibilité :\n",
    "        Les pipelines permettent d'automatiser l'ensemble du processus, garantissant que chaque étape est exécutée de manière cohérente. Cela rend également le processus reproductible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a456592-fd6b-4bef-a50d-7090b7b9e84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Définir les étapes du pipeline\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Standardiser les données\n",
    "    ('xgb', XGBClassifier(objective='binary:logistic', random_state=42))\n",
    "])\n",
    "\n",
    "# Définir les hyperparamètres à tester\n",
    "param_grid = {\n",
    "    'xgb__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'xgb__max_depth': [3, 6, 9],\n",
    "    'xgb__n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Configurer GridSearchCV avec le pipeline\n",
    "grid_search = GridSearchCV(estimator=xgb_pipeline, param_grid=param_grid, scoring='roc_auc', cv=3, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fonction pour évaluer et enregistrer les résultats de GridSearchCV dans MLflow\n",
    "def log_grid_search_cv_results(grid_search, X_train, y_train, X_test, y_test):\n",
    "    with mlflow.start_run():\n",
    "        # Loguer le type de modèle\n",
    "        mlflow.log_param(\"model_type\", \"Pipeline with XGBoost and GridSearchCV\")\n",
    "        \n",
    "        # Entraîner le GridSearchCV\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Logger tous les résultats de GridSearchCV\n",
    "        cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "        for i in range(len(cv_results)):\n",
    "            for key in cv_results.columns:\n",
    "                value = cv_results[key].iloc[i]\n",
    "                if isinstance(value, (float, int, np.number)):\n",
    "                    mlflow.log_metric(f\"{key}_{i}\", value)\n",
    "                elif isinstance(value, (list, dict)):\n",
    "                    # Convert lists or dicts to a string representation\n",
    "                    mlflow.log_param(f\"{key}_{i}\", str(value))\n",
    "        \n",
    "        # Enregistrer les meilleurs hyperparamètres\n",
    "        best_params = grid_search.best_params_\n",
    "        mlflow.log_params(best_params)\n",
    "        \n",
    "        # Afficher les meilleurs hyperparamètres\n",
    "        print(\"Best Hyperparameters:\", best_params)\n",
    "        \n",
    "        # Enregistrer le meilleur modèle\n",
    "        best_model = grid_search.best_estimator_\n",
    "        mlflow.sklearn.log_model(best_model, \"best_pipeline_model\")\n",
    "\n",
    "        # Sauvegarder le modèle localement dans le dossier 'models'\n",
    "        model_path = '../models/best_pipeline_model.pkl'\n",
    "        os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "        joblib.dump(best_model, model_path)\n",
    "        print(f\"Best model saved to {model_path}\")\n",
    "        \n",
    "        # Prédictions avec le meilleur modèle\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Évaluer les performances\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        fp = conf_matrix[0][1]\n",
    "        fn = conf_matrix[1][0]\n",
    "        cost = fp + 10 * fn\n",
    "        \n",
    "        # Logger les métriques\n",
    "        mlflow.log_metric(\"AUC\", auc)\n",
    "        mlflow.log_metric(\"Accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"Cost\", cost)\n",
    "        \n",
    "        print(f\"Best Model - AUC: {auc}\")\n",
    "        print(f\"Best Model - Accuracy: {accuracy}\")\n",
    "        print(f\"Best Model - Cost: {cost}\")\n",
    "\n",
    "# Exécuter la fonction pour loguer les résultats de GridSearchCV\n",
    "log_grid_search_cv_results(grid_search, X_train_resampled, y_train_resampled, X_test_scaled, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726e6e9d-745e-48b4-afe7-18e2c949bd2e",
   "metadata": {},
   "source": [
    "## Etude résultas model predict sur test\n",
    "\n",
    "Ce code effectue une analyse des résultats de prédiction d'un modèle sur un jeu de données de test. Il calcule des statistiques sur les prédictions, crée une matrice de confusion, trace la courbe ROC, et calcule des métriques de performance comme la précision, le rappel, et le F1-score. Il affiche également une distribution des probabilités de prédiction et liste les identifiants de clients pour lesquels le modèle a prédit 0 ou 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b631ee-9c79-475f-ba17-f5a6dc583f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_score, recall_score, f1_score\n",
    "\n",
    "# Charger le modèle sauvegardé\n",
    "model_path = '../models/best_pipeline_model.pkl'\n",
    "best_model = joblib.load(model_path)\n",
    "\n",
    "# Prédire les targets sur X_test_scaled\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "y_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calculer les métriques de performance\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "auc_score = roc_auc_score(y_test, y_proba)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Afficher les métriques\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(f\"AUC: {auc_score}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# Tracer la courbe ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {auc_score:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Tracer la distribution des probabilités de prédiction\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(y_proba, bins=50, color='blue', alpha=0.7)\n",
    "plt.title('Distribution of Prediction Probabilities')\n",
    "plt.xlabel('Prediction Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Analyser l'importance du seuil\n",
    "thresholds = np.arange(0.0, 1.1, 0.1)\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_adjusted = (y_proba >= threshold).astype(int)\n",
    "    precision_adjusted = precision_score(y_test, y_pred_adjusted)\n",
    "    recall_adjusted = recall_score(y_test, y_pred_adjusted)\n",
    "    f1_adjusted = f1_score(y_test, y_pred_adjusted)\n",
    "    \n",
    "    precisions.append(precision_adjusted)\n",
    "    recalls.append(recall_adjusted)\n",
    "    f1_scores.append(f1_adjusted)\n",
    "    \n",
    "    print(f\"Threshold: {threshold}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "    print(f\"Precision: {precision_adjusted}\")\n",
    "    print(f\"Recall: {recall_adjusted}\")\n",
    "    print(f\"F1 Score: {f1_adjusted}\\n\")\n",
    "\n",
    "# Tracer les métriques en fonction du seuil\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, precisions, label='Precision', marker='o')\n",
    "plt.plot(thresholds, recalls, label='Recall', marker='o')\n",
    "plt.plot(thresholds, f1_scores, label='F1 Score', marker='o')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Metrics at Different Thresholds')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ae9490-effb-4de2-817a-af7ee519531a",
   "metadata": {},
   "source": [
    "cout seuil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e16663-c78c-404f-a353-186e36c65355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58752844-40cb-440f-ab43-f38b9753ab5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc26c181-e9f2-4fdf-824f-7073319897a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d1af3d-5ed1-41c2-9cc6-f8b391896fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af4290b4-f4ca-46e4-a895-4f4a9903cc8f",
   "metadata": {},
   "source": [
    "## descriptions features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c581fb-18b4-4362-ba26-8d1add5b4644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le fichier de description des colonnes avec l'encodage correct\n",
    "try:\n",
    "    columns_description = pd.read_csv('../csv_files/HomeCredit_columns_description.csv', encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    columns_description = pd.read_csv('../csv_files/HomeCredit_columns_description.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Filtrer pour obtenir uniquement les descriptions pertinentes pour les caractéristiques utilisées dans l'application {train|test}\n",
    "feature_descriptions = columns_description[columns_description['Table'].str.contains('application_{train|test}.csv', na=False)]\n",
    "feature_descriptions = feature_descriptions[['Row', 'Description']].set_index('Row')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2f0670-64f9-4744-a336-80aa4b670415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99088fe7-61d1-4268-8127-7010c9cef19b",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ec1290-4ba0-4bdb-a579-d7b9a4286f65",
   "metadata": {},
   "source": [
    "## globale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11822c7-154e-449b-b583-4756df0e1354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "\n",
    "# Entraîner le meilleur modèle XGBoost avec les meilleurs hyperparamètres trouvés\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "#ajustement necessaire depuis qu'on utilise pipeline\n",
    "\n",
    "# Entraîner le meilleur modèle XGBoost avec les meilleurs hyperparamètres trouvés\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "best_model = best_pipeline.named_steps['xgb']  # Extraire le modèle XGBoost du pipeline\n",
    "\n",
    "\n",
    "# Extraire l'importance des caractéristiques\n",
    "importance = best_model.get_booster().get_score(importance_type='weight')\n",
    "\n",
    "# Convertir en DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': list(importance.keys()),\n",
    "    'Importance': list(importance.values())\n",
    "})\n",
    "\n",
    "# Assigner des noms significatifs aux features basées sur leur ordre dans les données d'origine\n",
    "feature_names = X_train.columns\n",
    "importance_df['Feature'] = importance_df['Feature'].apply(lambda x: feature_names[int(x[1:])])\n",
    "\n",
    "# Ajouter les descriptions des caractéristiques\n",
    "importance_df['Description'] = importance_df['Feature'].map(feature_descriptions['Description'])\n",
    "\n",
    "# Remplacer les valeurs NaN dans les descriptions par une chaîne vide pour éviter les erreurs\n",
    "importance_df['Description'] = importance_df['Description'].fillna('')\n",
    "\n",
    "# Trier les caractéristiques par importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Calculer le pourcentage d'importance\n",
    "importance_df['Importance'] = 100 * (importance_df['Importance'] / importance_df['Importance'].sum())\n",
    "\n",
    "# Afficher les 20 premières caractéristiques\n",
    "top_20_features = importance_df.head(20)\n",
    "\n",
    "plt.figure(figsize=(12, 8))  # Ajustez la taille de la figure pour plus de lisibilité\n",
    "plt.barh(top_20_features['Feature'], top_20_features['Importance'], color='skyblue')\n",
    "plt.xlabel('Importance (%)', fontsize=14)\n",
    "plt.title('Top 20 Feature Importance (XGBoost)', fontsize=16)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.show()\n",
    "\n",
    "# Afficher les descriptions des 20 premières caractéristiques\n",
    "descriptions = [f\"{feature}: {desc}\" for feature, desc in zip(top_20_features['Feature'], top_20_features['Description'])]\n",
    "\n",
    "# Utiliser print pour afficher les descriptions\n",
    "for description in descriptions:\n",
    "    print(description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fe697e-d38f-4562-93cc-1b16bbd711d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e82ed6-fecf-4580-8a0c-2e69af08c24e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f6ab5b-0de0-4082-8f5a-e15910183a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea89a582-3da1-4b28-908d-3d012c3e23cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10990df-3b7a-431e-a285-089a8d89725e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4011cf96-85be-4d9b-b3f4-74adc62a18d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c7fe681-69bd-4574-950e-fa995a7fc48a",
   "metadata": {},
   "source": [
    "## locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1c0ef2-933c-41a1-a030-a2d413c04f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Extraire le modèle XGBoost du pipeline\n",
    "best_model = best_pipeline.named_steps['xgb']  # Extraire le modèle XGBoost du pipeline\n",
    "\n",
    "\n",
    "# Créer un explainer SHAP pour le modèle XGBoost\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "\n",
    "# Sélectionner un client avec une cible de 0 et un client avec une cible de 1\n",
    "indices_target_0 = y_test[y_test == 0].index\n",
    "indices_target_1 = y_test[y_test == 1].index\n",
    "\n",
    "# Vérifier que les indices existent\n",
    "if len(indices_target_0) > 0:\n",
    "    index_target_0 = indices_target_0[0]\n",
    "    # Convertir l'index global en index relatif\n",
    "    relative_index_target_0 = y_test.index.get_loc(index_target_0)\n",
    "    X_target_0 = X_test_scaled[relative_index_target_0].reshape(1, -1)\n",
    "    shap_values_target_0 = explainer.shap_values(X_target_0)\n",
    "    \n",
    "    # Afficher l'analyse SHAP pour un client avec une cible de 0\n",
    "    print(\"Crédit accepté\")\n",
    "    shap.initjs()\n",
    "    shap.force_plot(explainer.expected_value, shap_values_target_0, X_target_0, feature_names=feature_names, matplotlib=True)\n",
    "\n",
    "if len(indices_target_1) > 0:\n",
    "    index_target_1 = indices_target_1[0]\n",
    "    # Convertir l'index global en index relatif\n",
    "    relative_index_target_1 = y_test.index.get_loc(index_target_1)\n",
    "    X_target_1 = X_test_scaled[relative_index_target_1].reshape(1, -1)\n",
    "    shap_values_target_1 = explainer.shap_values(X_target_1)\n",
    "    \n",
    "    # Afficher l'analyse SHAP pour un client avec une cible de 1\n",
    "    print(\"Crédit refusé\")\n",
    "    shap.initjs()\n",
    "    shap.force_plot(explainer.expected_value, shap_values_target_1, X_target_1, feature_names=feature_names, matplotlib=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab531c4-7903-4516-a974-ee68055aa20a",
   "metadata": {},
   "source": [
    "# temps de fin d'execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5d8969-7e72-40a1-b99f-4645f6a62af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marquer la fin de l'exécution\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculer le temps d'exécution total\n",
    "execution_time = end_time - start_time\n",
    "execution_time_str = str(datetime.timedelta(seconds=execution_time))\n",
    "\n",
    "print(f\"Exécution du notebook terminée à: {datetime.datetime.now()}\")\n",
    "print(f\"Temps d'exécution total: {execution_time_str}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3c96ed-d593-4609-aff1-bc7aa1a8ceb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4974b70a-9a6f-404e-9442-5ece1e10c0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assurez-vous que X_test est un DataFrame contenant 'SK_ID_CURR' et les autres features non-scalées\n",
    "# X_test_scaled est la version scalée de X_test, mais sans la colonne 'SK_ID_CURR'\n",
    "\n",
    "# Sélectionner un client avec une cible de 0 et un client avec une cible de 1\n",
    "indices_target_0 = y_test[y_test == 0].index\n",
    "indices_target_1 = y_test[y_test == 1].index\n",
    "\n",
    "# Vérifier que les indices existent\n",
    "if len(indices_target_0) > 0:\n",
    "    index_target_0 = indices_target_0[0]\n",
    "    SK_ID_CURR_target_0 = X_test.loc[index_target_0, 'SK_ID_CURR']\n",
    "    print(\"SK_ID_CURR pour un client avec cible 0:\", SK_ID_CURR_target_0)\n",
    "\n",
    "if len(indices_target_1) > 0:\n",
    "    index_target_1 = indices_target_1[0]\n",
    "    SK_ID_CURR_target_1 = X_test.loc[index_target_1, 'SK_ID_CURR']\n",
    "    print(\"SK_ID_CURR pour un client avec cible 1:\", SK_ID_CURR_target_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5af42b9-b38a-46d0-b639-a2108b2fcd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_datas['SK_ID_CURR']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ed5b7b-adcc-4d76-b0d2-89357fc0ce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Extraire le modèle XGBoost du pipeline\n",
    "best_model = best_pipeline.named_steps['xgb']  # Extraire le modèle XGBoost du pipeline\n",
    "\n",
    "# Faire des prédictions sur les données de test\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Sélectionner un client avec une prédiction de 0 et un client avec une prédiction de 1\n",
    "indices_pred_0 = np.where(y_pred == 0)[0]\n",
    "indices_pred_1 = np.where(y_pred == 1)[0]\n",
    "\n",
    "# Vérifier que les indices existent\n",
    "if len(indices_pred_0) > 0:\n",
    "    relative_index_pred_0 = indices_pred_0[0]\n",
    "    SK_ID_CURR_pred_0 = X_test.iloc[relative_index_pred_0]['SK_ID_CURR']\n",
    "    print(\"SK_ID_CURR pour un client avec une prédiction de 0:\", SK_ID_CURR_pred_0)\n",
    "\n",
    "if len(indices_pred_1) > 0:\n",
    "    relative_index_pred_1 = indices_pred_1[0]\n",
    "    SK_ID_CURR_pred_1 = X_test.iloc[relative_index_pred_1]['SK_ID_CURR']\n",
    "    print(\"SK_ID_CURR pour un client avec une prédiction de 1:\", SK_ID_CURR_pred_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea4dda7-3e20-43f6-b763-d198751728a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
